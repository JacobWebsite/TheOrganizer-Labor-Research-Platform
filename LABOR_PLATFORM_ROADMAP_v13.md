# Labor Relations Research Platform — Comprehensive Development Roadmap v13

**Date:** February 10, 2026
**Version:** 13.0 (supersedes v12 + ROADMAP_TO_DEPLOYMENT v3.0)
**Method:** 5-agent parallel audit (DB, API, Frontend, Data Sources, DevOps)
**Scope:** Complete development roadmap from current state to production-ready platform

---

## Executive Summary

### What's Been Built (Phases 0-4 Complete)

| Phase | Status | Key Deliverable |
|-------|--------|-----------------|
| Phase 0: Stabilize | COMPLETE | `.env`, connection pooling, pyproject.toml, GitHub push, 32 tests |
| Phase 1: Clean Foundation | COMPLETE | 99.2% NAICS, 99.8% geocoded, 100% hierarchy, 1,210 dedup merges |
| Phase 2: Scorecard Quick Wins | COMPLETE | OSHA normalization, geographic favorability, size refinement, siblings |
| Phase 3: Similarity Engine | COMPLETE | Gower distance, 269K comparables, mv_employer_features, API endpoint |
| Task 3.2: NLRB Patterns | COMPLETE | 33K elections analyzed, predicted win rates, ref tables |
| Phase 4: Frontend (5 sprints) | COMPLETE | Territory mode, deep dive, export, polish, 9,500+ lines |
| Quality Audit | COMPLETE | 20 critical bugs fixed, 44/44 tests passing |

### What's Left (This Roadmap)

| Domain | Hours Est. | Priority |
|--------|-----------|----------|
| **Data: Match Rate Improvements** | 35-45 | HIGH |
| **Data: New Sources** | 40-60 | HIGH |
| **API: Restructure & Harden** | 50-65 | HIGH |
| **Frontend: Production Polish** | 35-50 | MEDIUM |
| **DevOps: Deployment** | 40-55 | HIGH |
| **Analytics: Predictive Model** | 25-35 | MEDIUM |
| **Documentation & Launch** | 20-30 | HIGH |
| **Post-Launch Features** | 50-80 | LOW |
| **Total** | **~295-420 hrs** | |

---

## Current State Audit (February 10, 2026)

### Database: 33GB PostgreSQL, 90+ Tables

| Category | Tables | Total Rows | Status |
|----------|--------|-----------|--------|
| Core (unions, employers, relations) | 5 | ~210K | Excellent |
| NLRB (elections, participants, tallies) | 6 | ~2M | Excellent |
| OSHA (establishments, violations) | 4 | ~3.2M | Match rate needs work |
| WHD (wage theft) | 2 | ~694K | Match rate needs work |
| Corporate (crosswalk, hierarchy, GLEIF, SEC) | 8 | ~1.5M | Good |
| Mergent | 1 | 56,431 | NY-biased, needs expansion |
| Geography (density, QCEW, BLS) | 15+ | ~2.2M | Good |
| Reference (NLRB patterns, OSHA avgs, RTW) | 5 | ~430 | Good |
| 990 Filers | 2 | ~634K | **UNMATCHED** |
| NYC Violations | 10 | ~8.9K | Local only |
| Comparables | 1 | 269,810 | Good |

### Match Rate Summary (Critical Gap)

| Source | Records | Matched to F7 | Rate | Target |
|--------|---------|---------------|------|--------|
| OSHA Establishments | 1,007,217 | 79,981 | **7.9%** | >20% |
| WHD Wage Theft | 363,365 | ~17,000 | **4.8%** | >12% |
| IRS 990 National | 586,767 | 0 | **0.0%** | >2% |
| Mergent | 56,431 | ~3,400 | **6.0%** | >15% |
| Federal Contractors | 47,193 | 9,305 | 19.7% | OK |
| NLRB Participants | 1,906,542 | ~40K | 2.1% | >5% |

### API: 7,500+ Line Monolith

- **142+ endpoints** across 15 domains
- **Zero authentication** — anyone can access everything
- **CORS: allow_origins=["*"]** — wide open
- **No pagination** on most list endpoints (unbounded queries)
- **No rate limiting** — vulnerable to abuse
- **No request logging** — no audit trail
- **SQL via f-strings** — pattern is safe-but-fragile (whitelist values, not user input, but no Pydantic validation)
- **No API versioning** — breaking changes break all clients
- **Connection pooling** in place (ThreadedConnectionPool)
- **Health check** exists at `/api/health`
- **Swagger docs** auto-generated by FastAPI at `/docs`

### Frontend: 9,500+ Line HTML Monolith

- **3 app modes**: Territory (default), Search, Deep Dive
- **11 modals** after `</main>`
- **7 CDN dependencies**: Tailwind, Leaflet, Chart.js, MarkerCluster, Inter font, Heroicons, DOMPurify
- **No build step** — all inline JavaScript
- **Limited accessibility**: some ARIA labels on modals, no keyboard navigation, no skip-to-content, no screen reader announcements
- **No mobile responsiveness**: viewport meta exists but no media queries, no responsive breakpoints
- **Known deferred bugs**: territory map empty (scorecard lacks lat/lon), race conditions on rapid mode switching, metros API ignores state param
- **Memory management**: Chart.js instances tracked in `territoryCharts` (fixed in quality audit)
- **Export**: Print-to-PDF for territory + employer reports, CSV for targets + elections

---

## Roadmap: 8 Phases, 25 Checkpoints

### Phase 5: Match Rate Improvements
### Phase 6: New Data Sources
### Phase 7: API Restructure & Hardening
### Phase 8: Frontend Production Polish
### Phase 9: Deployment Infrastructure
### Phase 10: Predictive Analytics
### Phase 11: Documentation & Soft Launch
### Phase 12: Post-Launch Growth

---

## PHASE 5: Match Rate Improvements

**Goal:** Get more employers with complete profiles (violations, contracts, 990 data)
**Estimated:** 35-45 hours
**Why first:** Better match rates make the scorecard, similarity engine, and every employer profile more valuable. This is pure data quality with no infrastructure dependencies.

### Checkpoint 5.1: OSHA Advanced Matching (10-12 hrs)

**Current:** 7.9% (79,981 / 1,007,217). **Target:** >20%.

**Strategy (4 tiers):**

| Tier | Method | Expected Yield | Running Total |
|------|--------|---------------|---------------|
| A | Corporate parent matching (OSHA->Mergent->crosswalk->F7) | ~15,000 | ~95,000 (9.4%) |
| B | Address-first matching (street# + city + state) | ~40,000 | ~135,000 (13.4%) |
| C | Aggressive name normalization (strip store #, DBA, suffixes) | ~30,000 | ~165,000 (16.4%) |
| D | NAICS-constrained fuzzy (pg_trgm within same 2-digit) | ~40,000 | ~205,000 (20.3%) |

**Implementation:**
```python
# scripts/matching/osha_advanced_match.py
# Tier A: Corporate parent bridge
# 1. OSHA estab -> Mergent (fuzzy name+state)
# 2. Mergent -> crosswalk -> F7 employer_id
# 3. Insert into osha_f7_matches with match_method='corporate_parent'

# Tier B: Address matching
# 1. Extract street number from OSHA site_address
# 2. Match on street_num + city + state
# 3. Confirm with JaroWinkler name similarity >= 0.65

# Tier C: Name normalization
# 1. Strip patterns: r'#\d+', r'\bDBA\b.*', r'\bSTORE\b', r'\bFACILITY\b'
# 2. Apply cleanco + aggressive normalization
# 3. Match on normalized_name + state

# Tier D: NAICS-constrained fuzzy
# 1. Only compare within same 2-digit NAICS
# 2. pg_trgm similarity >= 0.45 (lower threshold, NAICS constraint prevents false positives)
```

**Validation checkpoint:** Spot-check 50 new matches from each tier. False positive rate should be <5%.

**Manual input ideal:** Review 50-100 borderline matches (similarity 0.45-0.55) to calibrate threshold.

### Checkpoint 5.2: WHD Matching Improvement (8-10 hrs)

**Current:** 4.8% (~17,000 / 363,365). **Target:** >12%.

**Strategy:**
1. **Trade name matching** — currently only `legal_name`; add `trade_name` as fallback (~5,000 new)
2. **Mergent bridge** — WHD -> Mergent (by EIN or name+city), then Mergent -> F7 via crosswalk (~3,000 new)
3. **Address matching** — WHD has street addresses; match on address+city+state (~4,000 new)
4. **Lower pg_trgm threshold** — reduce from 0.55 to 0.45 for WHD (noisier names, accept more candidates) (~5,000 new)

**Expected total:** ~34,000 matches (9.4%)

### Checkpoint 5.3: IRS 990 Matching (8-10 hrs)

**Current:** 0% (586,767 records, zero matched). **Largest untapped source.**

**Strategy:**
1. **EIN-based matching** — 990 filers have EIN; crosswalk has EIN for ~1,127 employers. Direct join. (~1,000)
2. **Name+state matching** — `organization_name` vs `employer_name_aggressive` + state (~5,000-10,000)
3. **Mergent bridge** — 990 EIN -> Mergent EIN -> crosswalk -> F7 (~2,000)

**Value add:** Revenue, total employees, executive compensation — fields not available from any other source. CEO-to-worker pay ratio is powerful organizing ammunition.

**Manual input ideal:** Review 990 organization names vs F7 employer names for nonprofit naming conventions (e.g., "The XYZ Foundation" vs "XYZ FOUNDATION INC").

### Checkpoint 5.4: Refresh & Validate (4-6 hrs)

After all match improvements:
- Update `corporate_identifier_crosswalk` with new links
- Refresh ALL materialized views (`REFRESH MATERIALIZED VIEW CONCURRENTLY`)
- Re-run Gower similarity computation with enriched features
- Re-run validation suite (44 tests)
- Save new baselines
- Compare scorecard rankings before/after — document which employers moved tiers

**Phase 5 Exit Criteria:**
- [ ] OSHA match rate > 15% (stretch: >20%)
- [ ] WHD match rate > 8% (stretch: >12%)
- [ ] 990 match rate > 1% (stretch: >3%)
- [ ] All 44 tests passing
- [ ] No regression in existing match quality

---

## PHASE 6: New Data Sources

**Goal:** Add high-value data that answers questions organizers actually ask
**Estimated:** 40-60 hours
**Dependencies:** None (can run in parallel with Phase 5)

### Checkpoint 6.1: FMCS Contract Expiration Data (8-10 hrs) — HIGH PRIORITY

**What:** Federal Mediation & Conciliation Service maintains records of all collective bargaining agreements filed, including expiration dates.

**Why critical:** Contract expiration is the #1 timing signal for organizing. When a contract expires, workers reassess their representation — this is when raids, decertifications, and new organizing are most likely.

**Data:** ~200K+ active CBAs with employer name, union, effective/expiration dates, worker count, industry.

**Access:** FMCS F-7 Notice Filing system. Data available via bulk download or FOIA request. Some available through data.gov.

**Matching strategy:** FMCS filings include employer name, union name, and state — match to F7 employers via name+state.

**Manual input required:** May need to submit FOIA request to FMCS for bulk data. User should initiate the request.

**New table:** `fmcs_contract_expirations` — employer_name, union_name, effective_date, expiration_date, worker_count, state, naics, matched_f7_employer_id.

**New API endpoint:** `GET /api/contracts/expiring?months=6&state=NY` — contracts expiring in next N months.

**Scorecard impact:** Add `score_contract_timing` — employers with expiring contracts in next 12 months get bonus points.

### Checkpoint 6.2: NLRB Real-Time Case Monitoring (6-8 hrs) — HIGH PRIORITY

**What:** Monitor NLRB for new petition filings (RC, RM, RD), ULP charges, and election results in near-real-time.

**Why:** Early awareness of organizing activity. "A new petition was just filed at [employer] in [city]" is actionable intelligence.

**Access:** NLRB provides case data at nlrb.gov/search/case. Can be scraped or accessed via their search API. RSS feeds may be available for new filings.

**Implementation:**
```python
# scripts/etl/nlrb_monitor.py
# 1. Query NLRB case search for filings in last 7 days
# 2. Compare against existing nlrb_elections table
# 3. Insert new cases
# 4. Generate alert digest (new petitions, election results, ULP charges)
# Schedule: daily via cron/Task Scheduler
```

**New table:** `nlrb_case_alerts` — case_number, filing_date, case_type, employer_name, union_name, state, alert_sent, matched_f7_employer_id.

**New API endpoint:** `GET /api/nlrb/alerts?days=7` — recent filings and results.

**Frontend:** Alert banner on territory dashboard showing recent NLRB activity in selected territory.

### Checkpoint 6.3: FEC Political Contribution Data (8-10 hrs) — MEDIUM PRIORITY

**What:** Federal Election Commission data on PAC contributions, corporate political spending, and lobbying disclosures.

**Why:** "This employer spent $500K lobbying against the PRO Act" or "This employer's PAC donated to anti-union candidates" is powerful organizing intelligence.

**Access:** 100% free. FEC bulk data downloads at fec.gov/data. OpenSecrets API (free tier: 200 calls/day).

**Data available:**
- PAC contributions by employer (committee disbursements)
- Individual contributions by employer (employer field in individual filings)
- Lobbying disclosures (LDA filings)

**Matching strategy:** FEC committee names often include employer names. Match PAC sponsors to F7 employers via name+state.

**New tables:**
- `fec_pac_contributions` — committee_name, employer_name, candidate, amount, election_cycle
- `fec_lobbying_disclosures` — registrant_name, client_name, amount, issues

**Manual input ideal:** Review top 100 PAC-to-employer matches for accuracy. FEC naming conventions differ from DOL.

### Checkpoint 6.4: DOL Enforcement Data Beyond WHD (6-8 hrs) — MEDIUM PRIORITY

**What:** Additional DOL enforcement agencies:
- **MSHA** (Mine Safety & Health Administration) — mining industry violations
- **OFCCP** (Office of Federal Contract Compliance) — federal contractor discrimination/compliance
- **EBSA** (Employee Benefits Security Administration) — pension/benefits violations

**Why:** More violation data = more employer profiles with leverage points. OFCCP is especially relevant for federal contractor targets.

**Access:**
- MSHA: Free bulk download at msha.gov/data-reports/data-sets (violation/inspection data)
- OFCCP: Enforcement data available via FOIA or DOL enforcement database
- EBSA: enforcement.dol.gov/data

**New tables:** `msha_violations`, `ofccp_violations`, `ebsa_violations`

**Scorecard impact:** Feed into `score_osha` (expanded to `score_safety_violations`) and `score_contracts` (OFCCP compliance).

### Checkpoint 6.5: Census County Business Patterns (4-6 hrs) — MEDIUM PRIORITY

**What:** Annual establishment counts by NAICS (6-digit) and county. More granular than QCEW for some dimensions.

**Why:** Provides the denominator for "how many employers exist in this industry in this area." Enables: "There are 340 nursing homes in Queens County; 45 are unionized (13%). Here are the top 10 non-union targets."

**Access:** Free. Census Bureau data.census.gov, bulk download as CSV.

**How it improves platform:** Currently QCEW gives industry x state. CBP gives industry x county. Combined with existing employer data, enables county-level market penetration analysis.

**New table:** `cbp_county_establishments` — fips, naics, establishments, employees, annual_payroll, year.

### Checkpoint 6.6: Mergent National Expansion (10-15 hrs) — HIGH PRIORITY

**What:** Expand Mergent Intellect data from NY-focused (56K employers) to national scope.

**Why:** Mergent is the richest employer intelligence source — revenue, employee counts, corporate parent-subsidiary chains, executive names, accurate NAICS. Currently 54K/56K unmatched employers are in NY state.

**Access:** Free via CUNY library Mergent Intellect access. Must be extracted manually through the library's web interface.

**Manual input REQUIRED:** User must access CUNY Mergent Intellect and run queries for each target state/industry. Export as CSV. Estimated 3-5 hours of manual data extraction.

**Strategy:**
1. Prioritize states with highest organizing activity (CA, IL, OH, PA, MI, WA, NJ, MA)
2. Within each state, prioritize high-organizing-potential industries (healthcare, hospitality, building services, manufacturing, transportation)
3. Load batches of 5K-10K employers per state
4. Match against F7 via Splink + name+state

**Target:** 150K-200K total Mergent employers (up from 56K).

### Checkpoint 6.7: State PERB Data (6-8 hrs) — MEDIUM PRIORITY

**What:** Public Employment Relations Board data from key states. Covers public-sector bargaining units, certifications, and negotiations.

**Data availability by state:**
- **NY PERB**: Representation cases searchable at perb.ny.gov. Some bulk data via FOIL.
- **CA PERB**: Case records at perb.ca.gov. Public records act request needed for bulk data.
- **IL ILRB**: Cases at illinois.gov/ilrb.
- **NJ PERC**: Cases at nj.gov/perc.
- **OH SERB**: serb.ohio.gov.

**Manual input required:** Each state PERB has a different format and access method. User may need to submit public records requests.

**Value:** Public sector organizing intelligence. Currently the platform is weak on public sector (only OLMS LM filings + ps_ tables).

**Phase 6 Exit Criteria:**
- [ ] FMCS contract expirations loaded and matched
- [ ] NLRB daily monitor script running
- [ ] FEC PAC data loaded for top 1,000 employers
- [ ] At least 1 additional DOL enforcement source loaded
- [ ] CBP county establishment counts loaded
- [ ] Mergent expanded to at least 3 additional states
- [ ] At least 1 state PERB dataset loaded

---

## PHASE 7: API Restructure & Hardening

**Goal:** Transform 7,500-line monolith into production-ready modular API
**Estimated:** 50-65 hours
**Dependencies:** Can start immediately, but complete before deployment (Phase 9)

### Checkpoint 7.1: Module Decomposition (12-16 hrs)

Split `labor_api_v6.py` into organized modules:

```
api/
  __init__.py
  main.py                    # FastAPI app, middleware, startup/shutdown
  config.py                  # Settings from .env (Pydantic BaseSettings)
  database.py                # Connection pool, get_db dependency injection
  middleware/
    __init__.py
    auth.py                  # JWT authentication middleware
    rate_limit.py            # Token bucket rate limiter
    logging.py               # Structured request/response logging
    error_handler.py         # Global exception handlers
  routers/
    __init__.py
    health.py                # /api/health, /api/summary, /api/stats
    lookups.py               # /api/lookups/*
    employers.py             # /api/employers/*
    unions.py                # /api/unions/*
    nlrb.py                  # /api/nlrb/*
    osha.py                  # /api/osha/*
    whd.py                   # /api/whd/*
    density.py               # /api/density/*
    trends.py                # /api/trends/*
    organizing.py            # /api/organizing/*, /api/sectors/*
    corporate.py             # /api/corporate/*
    projections.py           # /api/projections/*
    contracts.py             # /api/contracts/* (new - FMCS)
    alerts.py                # /api/nlrb/alerts (new)
    admin.py                 # /api/admin/* (user management)
  models/
    __init__.py
    schemas.py               # Pydantic response models
    queries.py               # SQL query constants
```

**Approach:** One router file per domain. Move SQL into named constants. Use FastAPI dependency injection for database connections. Keep backward-compatible URLs.

**Validation:** All 44 existing tests must pass after decomposition. No URL changes.

### Checkpoint 7.2: Pagination & Input Validation (8-10 hrs)

**Pagination:** All list endpoints get `offset` + `limit` with defaults:
```python
@router.get("/api/employers/search")
async def search_employers(
    q: str = Query(None, min_length=1, max_length=200),
    state: str = Query(None, regex="^[A-Z]{2}$"),
    limit: int = Query(50, ge=1, le=500),
    offset: int = Query(0, ge=0),
    db = Depends(get_db)
):
```

**Input validation via Pydantic:**
- State codes: 2-letter uppercase, validated against known list
- NAICS codes: 2-6 digit numeric
- Establishment IDs: alphanumeric
- Search queries: max 200 chars, sanitized
- Sort fields: whitelist of allowed column names

**Affected endpoints (unbounded today):**
- `/api/employers/search` — can return 60K+ rows
- `/api/unions/search` — can return 26K+ rows
- `/api/nlrb/elections/search` — can return 33K+ rows
- `/api/osha/establishments/search` — can return 1M+ rows
- `/api/density/by-county` — returns 3,144 rows
- `/api/whd/search` — can return 363K+ rows
- All sector target endpoints

### Checkpoint 7.3: Authentication & Authorization (12-15 hrs)

**JWT Implementation:**
```python
# api/middleware/auth.py
# 1. User table: id, email, password_hash, role, created_at, last_login
# 2. Roles: admin, organizer, viewer, api_key
# 3. Endpoints:
#    POST /api/auth/register (admin only)
#    POST /api/auth/login -> returns JWT
#    POST /api/auth/refresh -> refreshes JWT
#    GET  /api/auth/me -> current user info
#    POST /api/auth/api-key -> generate API key (admin only)
# 4. JWT payload: {user_id, email, role, exp}
# 5. Token expiry: 24h access, 7d refresh
```

**Role-based access:**
- `admin`: full access, user management
- `organizer`: read all data, export, no admin
- `viewer`: read-only, no export
- `api_key`: programmatic access, rate-limited

**CORS lockdown:** Replace `allow_origins=["*"]` with specific origins (platform domain + localhost for dev).

**Manual input required:** Admin user credentials need to be set during initial deployment.

### Checkpoint 7.4: Error Handling & Logging (6-8 hrs)

**Structured logging:**
```python
# Every request logs: method, path, user_id, duration_ms, status_code
# Every error logs: traceback, request context, user context
# Format: JSON for machine parsing
import structlog
logger = structlog.get_logger()
```

**Global error handling:**
```python
@app.exception_handler(Exception)
async def global_handler(request, exc):
    logger.error("unhandled_error", path=request.url.path, error=str(exc))
    return JSONResponse(status_code=500, content={"error": "Internal server error"})
```

**Consistent error response shape:**
```json
{
  "error": "Not found",
  "detail": "Employer with ID 999999 not found",
  "status_code": 404
}
```

### Checkpoint 7.5: API Versioning & Documentation (4-6 hrs)

**Versioning:** Prefix all endpoints with `/api/v1/`. Keep backward-compatible `/api/` alias for transition period.

**Enhanced Swagger docs:**
- Response model annotations for all endpoints
- Example values in schemas
- Tag descriptions for each domain
- Authentication flow documented

**Phase 7 Exit Criteria:**
- [ ] API split into 15+ router modules
- [ ] All endpoints have pagination (limit/offset)
- [ ] All inputs validated via Pydantic models
- [ ] JWT authentication working with 4 roles
- [ ] CORS locked to specific origins
- [ ] Structured JSON logging on all requests
- [ ] All 44+ tests passing
- [ ] API versioning (/api/v1/) in place

---

## PHASE 8: Frontend Production Polish

**Goal:** Make the frontend accessible, mobile-friendly, and robust
**Estimated:** 35-50 hours
**Dependencies:** API restructure (Phase 7) should be at least at Checkpoint 7.2

### Checkpoint 8.1: Code Architecture Refactor (8-10 hrs)

**Current problem:** 9,500+ lines of inline JavaScript in a single HTML file. No module system, no build step, global state scattered across variables.

**Approach:** Keep single-file architecture (no build tooling) but organize code:

1. **Extract CSS to external file** — `styles/organizer.css` (~800 lines)
2. **Extract JS modules** — Use ES6 `<script type="module">` with separate files:
   ```
   js/
     app.js          # App initialization, mode switching, global state
     api.js          # All fetch() calls, error handling, retry logic
     territory.js    # Territory dashboard rendering
     search.js       # Search mode logic
     deepdive.js     # Deep dive employer profile
     charts.js       # Chart.js wrapper with cleanup
     map.js          # Leaflet map management
     export.js       # PDF/CSV export logic
     utils.js        # escapeHtml, formatNumber, etc.
   ```
3. **Centralize state management:**
   ```javascript
   const AppState = {
     mode: 'territory',
     territory: { unionId: null, state: null, metro: null, data: {} },
     search: { query: '', filters: {}, results: [] },
     deepDive: { employerId: null, data: {}, returnMode: 'territory' },
     charts: {},  // Track all Chart.js instances
     map: null    // Leaflet map instance
   };
   ```

### Checkpoint 8.2: Accessibility (WCAG 2.1 AA) (8-10 hrs)

**Current gaps and fixes:**

| Issue | Fix | Priority |
|-------|-----|----------|
| No skip-to-content link | Add `<a href="#main" class="sr-only focus:not-sr-only">Skip to content</a>` | HIGH |
| No keyboard navigation for tables | Add `tabindex="0"` on interactive rows, Enter/Space to activate | HIGH |
| No focus management on mode switch | `document.getElementById(target).focus()` after transition | HIGH |
| Modal focus trap missing | Trap Tab/Shift+Tab within open modals | HIGH |
| No ARIA live regions | `aria-live="polite"` on dynamic content areas (results, loading) | MEDIUM |
| No screen reader announcements | Announce search results count, loading state, errors | MEDIUM |
| Color contrast on score bars | Ensure 4.5:1 ratio on all score bar text | MEDIUM |
| No alt text on map markers | Add descriptive tooltips to Leaflet markers | LOW |
| Form labels not associated | `<label for="...">` on all form controls | MEDIUM |

### Checkpoint 8.3: Mobile Responsiveness (6-8 hrs)

**Current state:** Viewport meta tag exists, no responsive design.

**Implementation:**
```css
/* Responsive breakpoints */
@media (max-width: 1024px) {
  /* Tablet: stack sidebar, simplify data tables */
  .territory-grid { grid-template-columns: 1fr; }
  .data-table { font-size: 0.85rem; }
}

@media (max-width: 768px) {
  /* Mobile: full-width cards, hide non-essential columns */
  .mode-toggle { flex-direction: column; }
  .kpi-cards { grid-template-columns: 1fr 1fr; }
  .score-breakdown { flex-direction: column; }
  /* Hide map on mobile, show list view */
  .territory-map { display: none; }
}

@media (max-width: 480px) {
  /* Small mobile: single column everything */
  .kpi-cards { grid-template-columns: 1fr; }
  header { flex-direction: column; gap: 0.5rem; }
}
```

**Touch targets:** All clickable elements minimum 44x44px.

**Map:** On mobile, replace full Leaflet map with a "View Map" button that opens map in full-screen overlay.

### Checkpoint 8.4: Error Recovery & Loading States (6-8 hrs)

**Current:** Basic loading skeletons and error retry on some sections. Needs consistency.

**Improvements:**
1. **Offline detection:** Show banner when network unavailable
2. **API timeout handling:** Show specific message after 10s, retry button
3. **Partial failure:** If 3/7 territory API calls fail, show data for the 4 that succeeded + error state for the 3 that failed (don't blank the whole dashboard)
4. **Stale data indicator:** "Data last updated: 2 hours ago" on territory dashboard
5. **Empty state design:** When search returns 0 results, show helpful suggestions
6. **Rate limit feedback:** If API returns 429, show "Too many requests, please wait" with countdown

### Checkpoint 8.5: UX Improvements (6-8 hrs)

**Quick wins:**
1. **URL routing** — Use `history.pushState` so browser back button works between modes. Deep-linkable URLs like `#/territory/SEIU/NY` or `#/employer/12345`
2. **Search history** — Remember last 5 searches in localStorage
3. **Keyboard shortcuts** — `Ctrl+K` for search, `Escape` to close modals, `T` for territory, `S` for search
4. **Loading progress** — Show "Loading 3 of 7 data sources..." instead of generic spinner
5. **Comparison mode** — Select 2-3 employers and compare side-by-side
6. **Score explanation tooltips** — Hover over each score bar segment for plain-English explanation

**Phase 8 Exit Criteria:**
- [ ] JavaScript extracted to separate module files
- [ ] WCAG 2.1 AA compliance (automated check with axe-core)
- [ ] Usable on mobile (768px and 480px breakpoints)
- [ ] All API errors gracefully handled with retry
- [ ] Browser back button works across modes
- [ ] Keyboard shortcuts functional

---

## PHASE 9: Deployment Infrastructure

**Goal:** Platform accessible at a URL with HTTPS, authentication, and monitoring
**Estimated:** 40-55 hours
**Dependencies:** Phase 7 (API hardening) must be complete

### Checkpoint 9.1: Containerization (8-10 hrs)

**Dockerfile (API):**
```dockerfile
FROM python:3.12-slim AS builder
WORKDIR /app
COPY pyproject.toml .
RUN pip install --no-cache-dir -e .

FROM python:3.12-slim
WORKDIR /app
COPY --from=builder /usr/local/lib/python3.12/site-packages /usr/local/lib/python3.12/site-packages
COPY . .
EXPOSE 8001
CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8001"]
```

**docker-compose.yml:**
```yaml
services:
  api:
    build: .
    ports: ["8001:8001"]
    env_file: .env
    depends_on: [db]
  db:
    image: postgres:16
    volumes: ["pgdata:/var/lib/postgresql/data"]
    environment:
      POSTGRES_DB: olms_multiyear
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    ports: ["5432:5432"]
  nginx:
    image: nginx:alpine
    ports: ["80:80", "443:443"]
    volumes: ["./nginx.conf:/etc/nginx/nginx.conf", "./files:/usr/share/nginx/html"]
volumes:
  pgdata:
```

**Database migration:** Export with `pg_dump --format=custom olms_multiyear > backup.dump`, restore into Docker container.

### Checkpoint 9.2: Cloud Hosting Selection & Setup (10-12 hrs)

**Cost comparison (monthly estimates for 33GB Postgres + API):**

| Provider | Database | API Server | Total/mo | Pros | Cons |
|----------|----------|-----------|----------|------|------|
| **DigitalOcean** | Managed Postgres $60 | Droplet $24 | **$84** | Simple, predictable pricing | Manual scaling |
| **Railway** | Postgres $20+usage | API $5+usage | **$40-80** | Easy deploy, auto-scale | 33GB may hit limits |
| **Render** | Postgres $20 | Web Service $7 | **$27** | Cheapest, auto-deploy from Git | 90GB disk limit |
| **Fly.io** | Postgres $15+storage | Machine $7 | **$35-50** | Edge deployment, fast | More complex setup |
| **AWS (EC2+RDS)** | RDS t3.medium $70 | EC2 t3.small $15 | **$85+** | Enterprise features | Complex, costly |

**Recommendation:** Start with **Render** ($27/mo) for MVP. Migrate to **DigitalOcean** ($84/mo) if you need more resources or longer-term stability.

**Manual input required:** User needs to create account on chosen platform, set up billing.

### Checkpoint 9.3: CI/CD Pipeline (6-8 hrs)

**GitHub Actions workflow:**
```yaml
# .github/workflows/deploy.yml
name: Test and Deploy
on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_DB: olms_multiyear_test
          POSTGRES_PASSWORD: test
        ports: ["5432:5432"]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: "3.12" }
      - run: pip install -e ".[dev]"
      - run: pytest tests/ -v

  deploy:
    needs: test
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      # Deploy to chosen platform
```

**Branch strategy:** `main` = production, `develop` = staging. PRs required for main.

### Checkpoint 9.4: Domain, SSL & DNS (3-4 hrs)

- Register domain (e.g., `laborplatform.org` or `organizer.tools`)
- Configure DNS to point to hosting provider
- SSL via Let's Encrypt (auto-provisioned by most PaaS providers)
- Redirect HTTP -> HTTPS

**Manual input required:** User must choose and register domain name.

### Checkpoint 9.5: Monitoring & Alerting (4-6 hrs)

| Tool | Purpose | Cost |
|------|---------|------|
| UptimeRobot | Uptime monitoring, alerts | Free (50 monitors) |
| Sentry | Error tracking, crash reports | Free (5K events/mo) |
| PostgreSQL pg_stat | Query performance monitoring | Free (built-in) |
| Structured logs | Request audit trail | Free (stdout -> provider log viewer) |

### Checkpoint 9.6: Data Pipeline Automation (8-10 hrs)

**ETL orchestration** — Simple cron-based approach (no Airflow overhead):

```python
# scripts/etl/orchestrate.py
# DAG definition:
PIPELINE = [
    # Stage 1: Data fetching (parallel)
    {"name": "fetch_nlrb", "script": "scripts/etl/nlrb_monitor.py", "schedule": "daily"},
    {"name": "fetch_osha", "script": "scripts/etl/extract_osha_resume.py", "schedule": "quarterly"},
    {"name": "fetch_whd", "script": "scripts/etl/load_whd_national.py", "schedule": "quarterly"},
    {"name": "fetch_qcew", "script": "scripts/etl/fetch_qcew.py", "schedule": "quarterly"},

    # Stage 2: Matching (sequential, after fetch)
    {"name": "match_osha", "script": "scripts/matching/osha_advanced_match.py", "depends": ["fetch_osha"]},
    {"name": "match_whd", "script": "scripts/scoring/match_whd_to_employers.py", "depends": ["fetch_whd"]},

    # Stage 3: Scoring & refresh
    {"name": "rescore", "script": "scripts/scoring/rescore_phase2.py", "depends": ["match_osha", "match_whd"]},
    {"name": "refresh_views", "script": "scripts/maintenance/refresh_materialized_views.py", "depends": ["rescore"]},

    # Stage 4: Validation
    {"name": "validate", "script": "scripts/validation/run_all_checks.py", "depends": ["refresh_views"]},
]
```

**Update schedule:**

| Source | Frequency | Automation |
|--------|-----------|------------|
| OLMS LM filings | Annual (March) | Semi-auto (download + script) |
| NLRB cases | Daily | Full auto |
| OSHA violations | Quarterly | Semi-auto |
| WHD cases | Quarterly | Semi-auto |
| BLS density/QCEW | Annual | Semi-auto |
| FMCS contracts | Monthly | Semi-auto |
| FEC contributions | Quarterly | Full auto (API) |
| Mergent | As needed | **Manual** (CUNY library) |

**Phase 9 Exit Criteria:**
- [ ] Docker containers build and run locally
- [ ] Application deployed to cloud provider
- [ ] HTTPS with valid SSL certificate
- [ ] CI/CD: tests run on push, deploy on merge to main
- [ ] Monitoring: uptime checks + error tracking active
- [ ] ETL orchestrator documented with update schedule
- [ ] Database backup strategy in place (daily pg_dump)

---

## PHASE 10: Predictive Analytics

**Goal:** Move from heuristic scoring to data-driven predictions
**Estimated:** 25-35 hours
**Dependencies:** Phase 5 (match rates) must be complete for richer features

### Checkpoint 10.1: Historical Outcome Validation (10-12 hrs)

**What:** Test whether the current scorecard actually predicts organizing success.

**Method:**
1. Build features-plus-outcome dataset from 33,096 NLRB elections
2. Temporal split: pre-2022 training (~25K), 2022-2024 test (~8K)
3. For each election employer, compute the scorecard score using only data available BEFORE the election date
4. Measure correlation: do higher-scored employers actually win elections more?

**Metrics:**
- AUC-ROC (>0.65 = useful, >0.75 = good, <0.55 = not better than random)
- Precision@50 (of the top 50 scored targets, how many actually won elections?)
- Feature importance ranking (which factors actually matter?)

**If AUC > 0.65:** Current scorecard is validated. Publish confidence.
**If AUC < 0.55:** Scorecard needs rebuilt with data-derived weights (Checkpoint 10.2).

### Checkpoint 10.2: Propensity Score Model (10-14 hrs)

**What:** Logistic regression that predicts P(unionized | employer features).

**Training data:**
- Positive class: F7 employers (60,953 confirmed union)
- Negative class: Mergent non-union employers + NLRB election losers + OSHA establishments with no union link

**Features:**
- NAICS 2-digit sector (categorical)
- Employee count (log-transformed)
- State (categorical)
- OSHA violation ratio to industry average (numeric)
- Has government contracts (binary)
- Has wage theft violations (binary)
- Revenue bucket (ordinal)
- Industry union density (numeric)
- Right-to-work state (binary)
- NLRB state win rate (numeric)
- BLS employment growth projection (numeric)

**Output:** Propensity score 0-100 for every non-union employer. This BECOMES the organizing score.

**Validation:** 5-fold cross-validation on training set. Holdout test on 2022-2024 elections.

### Checkpoint 10.3: Composite Opportunity Score (5-8 hrs)

**Final scoring formula (from "Every Method for Classifying Businesses"):**

```
Opportunity Score = 0.35 x Similarity + 0.35 x Vulnerability + 0.30 x Feasibility
```

Where:
- **Similarity** = Gower distance to nearest unionized employers (already computed)
- **Vulnerability** = OSHA violations + WHD violations + contract leverage + political spending
- **Feasibility** = Size sweet spot + geographic favorability + NLRB win rate + contract timing

Weights (0.35/0.35/0.30) replaced by empirically optimal weights from outcome validation.

**Phase 10 Exit Criteria:**
- [ ] Current scorecard validated against NLRB outcomes (AUC reported)
- [ ] Propensity model trained and evaluated
- [ ] Opportunity Score formula finalized with empirical weights
- [ ] All employers re-scored with new methodology
- [ ] Old and new rankings compared (correlation report)

---

## PHASE 11: Documentation & Soft Launch

**Goal:** Platform is documented, user-tested, and launched to beta users
**Estimated:** 20-30 hours
**Dependencies:** Phases 7-9 should be complete

### Checkpoint 11.1: User Documentation (6-8 hrs)

**Deliverables:**
1. **Quick Start Guide** — 1-page "How to use the Organizer" with screenshots
2. **Feature Guide** — Territory dashboard, search, employer profiles, exports
3. **Data Methodology** — Where data comes from, how matching works, how scoring works
4. **FAQ** — Common questions about data accuracy, update frequency, coverage

**Format:** In-app help pages (accessible from `?` icon in header).

### Checkpoint 11.2: Developer Documentation (4-6 hrs)

**Deliverables:**
1. **API Reference** — Enhanced Swagger docs with examples for each endpoint
2. **Database ERD** — Visual entity-relationship diagram (generated from schema)
3. **Architecture Overview** — System diagram showing data flow
4. **Contribution Guide** — How to add new data sources, new API endpoints, new frontend features

### Checkpoint 11.3: Data Methodology Audit (6-8 hrs)

**What:** Have 2-3 labor researchers or economists review the methodology.

**Review areas:**
- Membership counting methodology (deduplication approach)
- Scorecard factor selection and weighting
- Similarity engine methodology (Gower distance parameter choices)
- NLRB prediction model (if built)
- Data source provenance and update frequency

**Manual input required:** User should identify and contact reviewers (labor economists, researchers, or experienced organizers). Provide them with methodology document and sample outputs.

### Checkpoint 11.4: Beta Testing (4-6 hrs)

**Target:** 3-5 beta testers (union organizers, researchers, or labor data practitioners).

**Testing protocol:**
1. Give each tester a specific task: "Find the top 5 organizing targets for [union] in [state]"
2. Time how long it takes (target: under 5 minutes)
3. Structured feedback form: usefulness, accuracy, ease of use, missing features
4. Bug reports triaged and critical fixes applied

**Manual input required:** User must recruit beta testers and coordinate testing sessions.

**Phase 11 Exit Criteria:**
- [ ] Quick Start Guide published in-app
- [ ] API docs enhanced with examples
- [ ] At least 2 external methodology reviewers engaged
- [ ] At least 3 beta testers completed testing
- [ ] Critical feedback addressed
- [ ] No show-stopping bugs remaining

---

## PHASE 12: Post-Launch Growth

**Goal:** Continuously improve the platform based on user feedback and new data
**Estimated:** 50-80 hours (ongoing)
**Priority ordering by impact:**

### Checkpoint 12.1: Contract Expiration Alerts (8-10 hrs) — HIGH

**What:** Email/notification alerts when contracts in a user's territory are expiring in the next 3/6/12 months.

**Requires:** FMCS data (Phase 6.1) + user accounts (Phase 7.3) + email service (SendGrid free tier).

### Checkpoint 12.2: CPS Microdata for Granular Density (10-12 hrs) — MEDIUM

**What:** IPUMS CPS microdata for custom union density at industry x geography x occupation intersections. Currently BLS only publishes ~50 industry categories; CPS microdata allows arbitrary cross-tabulations.

**Source:** unionstats.com (Hirsch & Macpherson) for pre-computed state x industry tables. IPUMS for raw microdata.

### Checkpoint 12.3: Occupation Mix Comparison (10-14 hrs) — MEDIUM

**What:** BLS OEWS staffing patterns show what SOC codes exist at each NAICS. Two employers in different NAICS but with similar occupation mixes (lots of nurses, janitors, drivers) are comparable for organizing.

**Method:** Cosine similarity on occupation vectors derived from OEWS staffing patterns.

**Value:** Enables cross-industry comparisons: "This non-union call center has a similar workforce composition to this unionized call center, even though they're in different NAICS codes."

### Checkpoint 12.4: Text-Based Employer Embedding (15-20 hrs) — FUTURE

**What:** Sentence-BERT embeddings of company descriptions/job postings. Cosine similarity between employer vectors for nuanced matching that goes beyond structured data.

**From "Every Method" research:** Outperforms NAICS for identifying comparable businesses.

**Requires:** Company description data (LinkedIn profiles, websites, job postings). Scraping or API access needed.

### Checkpoint 12.5: Multi-Tenant Union Views (10-12 hrs) — FUTURE

**What:** Each union organization gets their own "workspace" showing only their territory, their employers, their targets. Union A can't see Union B's internal notes or priority rankings.

**Requires:** User accounts (Phase 7.3) + union affiliation mapping + view-level access control.

### Checkpoint 12.6: Campaign Tracking (12-15 hrs) — FUTURE

**What:** Let organizers mark employers as "active campaign", track stages (research -> outreach -> petition -> election -> contract), and record outcomes.

**New tables:** `campaigns`, `campaign_events`, `campaign_notes`

**Value:** Over time, builds proprietary outcome data that feeds back into the predictive model (Phase 10).

### Checkpoint 12.7: News & Media Monitoring (10-12 hrs) — FUTURE

**What:** Automatically scan news for labor-related stories — strikes, organizing drives, employer controversies — and link to employers in the database.

**Approach:** News API (newsapi.org, $449/mo) or Google News RSS (free but rate-limited). NLP entity extraction to match employer names.

---

## Summary Timeline & Critical Path

```
Phase 5 (Match Rates)     ████████████           Weeks 1-3
Phase 6 (New Data)         ░░██████████████       Weeks 2-6
Phase 7 (API Hardening)       ████████████████    Weeks 3-7
Phase 8 (Frontend Polish)        ████████████     Weeks 5-8
Phase 9 (Deployment)                ██████████    Weeks 7-10
Phase 10 (Analytics)            ░░░░██████████    Weeks 6-10
Phase 11 (Launch)                       ████████  Weeks 9-12
Phase 12 (Growth)                          ████>  Weeks 12+

████ = Active work
░░░░ = Can start early (parallel track)
```

**Critical path:**
```
Phase 5 -> Phase 10 (match rates enable richer model)
Phase 7 -> Phase 9 (API hardening before deployment)
Phase 9 -> Phase 11 (deployment before launch)
```

**Parallelizable:**
- Phase 5 + Phase 6 (different data pipelines)
- Phase 7 + Phase 8 (backend + frontend)
- Phase 6 + Phase 7 (new data + API restructure)

### Time Estimates

| Pace | Total Time | Completion |
|------|-----------|------------|
| 10 hrs/week | 30-42 weeks | Oct-Dec 2026 |
| 15 hrs/week | 20-28 weeks | Jul-Sep 2026 |
| 20 hrs/week | 15-21 weeks | Jun-Aug 2026 |
| Full-time (40 hrs/week) | 8-11 weeks | Apr-May 2026 |

### Minimum Viable Deployment (~150 hours)

If you want to ship something fast, cut to:

1. **Phase 5** (match rates) — 35 hrs — makes everything more useful
2. **Phase 7 reduced** (auth + pagination only) — 25 hrs — minimum for deployment
3. **Phase 9 reduced** (Docker + Render + SSL) — 20 hrs — get it online
4. **Phase 11 reduced** (Quick Start Guide + 3 beta testers) — 15 hrs — validate with users

Skip: Frontend refactor (ship current HTML), predictive model (use current scorecard), new data sources (add post-launch).

**That gives:** Deployed platform with auth, better match rates, improved scorecard, current frontend, accessible at a URL. ~95 hours, ~6-10 weeks.

---

## Where Manual Input Is Required

| Checkpoint | Manual Input Needed | Estimated Time |
|-----------|---------------------|----------------|
| 5.1 | Review 50-100 borderline OSHA matches | 1-2 hrs |
| 5.3 | Review 990 nonprofit naming conventions | 1 hr |
| 6.1 | Submit FOIA request to FMCS | 1 hr + wait time |
| 6.3 | Review top 100 PAC-to-employer matches | 2-3 hrs |
| 6.6 | **Extract Mergent data via CUNY library** | **3-5 hrs** |
| 6.7 | Submit PERB public records requests | 1-2 hrs |
| 7.3 | Set admin user credentials | 15 min |
| 9.2 | Create hosting account, set up billing | 30 min |
| 9.4 | Choose and register domain name | 30 min |
| 11.3 | Identify and contact methodology reviewers | 2-3 hrs |
| 11.4 | Recruit beta testers, coordinate testing | 3-4 hrs |

**Total manual input:** ~15-20 hours spread across the roadmap.

---

## Technical Debt Tracker (Updated)

| ID | Severity | Description | Phase | Status |
|----|----------|-------------|-------|--------|
| TD-01 | Resolved | SQL injection via f-strings | 0.1 | Safe (whitelist pattern) |
| TD-02 | Resolved | Hardcoded DB password | 0.1 | FIXED (.env) |
| TD-03 | **CRITICAL** | Zero authentication on 142 endpoints | 7.3 | |
| TD-04 | **HIGH** | CORS allow_origins=["*"] | 7.3 | |
| TD-05 | **HIGH** | 7,500-line monolith API | 7.1 | |
| TD-06 | **HIGH** | 9,500-line monolith frontend | 8.1 | |
| TD-07 | Resolved | No connection pooling | 0.4 | FIXED |
| TD-08 | **HIGH** | 11+ endpoints return unbounded results | 7.2 | |
| TD-09 | Resolved | No dependency management | 0.3 | FIXED |
| TD-10 | MEDIUM | Project in Downloads folder | 9.1 | |
| TD-11 | Resolved | No database backup strategy | 0.2 | FIXED |
| TD-12 | **HIGH** | 990 national (586K) unmatched | 5.3 | |
| TD-13 | **HIGH** | OSHA match rate 7.9% | 5.1 | |
| TD-14 | **HIGH** | WHD match rate 4.8% | 5.2 | |
| TD-15 | Resolved | Missing geocodes | 1.3 | FIXED (99.8%) |
| TD-16 | Resolved | Missing NAICS | 1.2 | FIXED (99.2%) |
| TD-17 | MEDIUM | Scorecard weights unvalidated | 10.1 | |
| TD-18 | MEDIUM | ETL hardcoded to Windows paths | 9.6 | |
| TD-19 | MEDIUM | 440 scripts with no orchestration | 9.6 | |
| TD-20 | MEDIUM | Silent exception swallowing in API | 7.4 | |
| TD-21 | MEDIUM | No request logging | 7.4 | |
| TD-22 | Resolved | No tests | 0.5 | FIXED (44/44) |
| TD-23 | MEDIUM | No CI/CD pipeline | 9.3 | |
| TD-24 | MEDIUM | Python 3.14-specific code | 9.1 | Target 3.12 |
| TD-25 | LOW | No rate limiting | 7.3 | |
| TD-26 | MEDIUM | No accessibility (WCAG) | 8.2 | NEW |
| TD-27 | MEDIUM | No mobile responsiveness | 8.3 | NEW |
| TD-28 | LOW | No URL routing (back button broken) | 8.5 | NEW |
| TD-29 | HIGH | Territory map empty (no lat/lon on scorecard) | 8.4 | Known deferred |
| TD-30 | LOW | Race conditions on rapid mode switching | 8.4 | Known deferred |

---

## Risk Register (Updated)

| ID | Risk | Likelihood | Impact | Mitigation |
|----|------|-----------|--------|------------|
| R-01 | Scorecard validation fails (AUC < 0.55) | Medium | HIGH | Phase 10 includes rebuild path |
| R-02 | Database too large for affordable hosting | Low | HIGH | Start with 33GB, archive pre-2015 if needed |
| R-03 | Laptop failure | Low | LOW | MITIGATED (GitHub) |
| R-04 | Python 3.14 incompatibilities | Medium | MEDIUM | Target 3.12 for Docker |
| R-05 | Mergent data license restricts redistribution | Medium | HIGH | Check terms before deploying Mergent fields |
| R-06 | No beta testers available | Low | HIGH | Pre-recruit before Phase 11 |
| R-07 | FMCS FOIA takes months | Medium | LOW | Start early, use other sources meanwhile |
| R-08 | Hosting costs exceed budget | Low | MEDIUM | Start with Render ($27/mo), upgrade as needed |
| R-09 | Single-developer bus factor | HIGH | CRITICAL | Documentation (Phase 11.2) |
| R-10 | Scope creep from Phase 12 | Medium | MEDIUM | Phase 12 is post-launch, strict prioritization |
| R-11 | OSHA/WHD data freshness lapses | Medium | MEDIUM | Pipeline automation (Phase 9.6) |
| R-12 | Frontend grows past maintainability | Medium | MEDIUM | Phase 8.1 module extraction |

---

## Complete Checkpoint Summary

| # | Checkpoint | Hours | Dependencies | Manual Input? |
|---|-----------|-------|-------------|---------------|
| 5.1 | OSHA Advanced Matching | 10-12 | None | Review borderline matches |
| 5.2 | WHD Matching Improvement | 8-10 | None | No |
| 5.3 | IRS 990 Matching | 8-10 | None | Review naming conventions |
| 5.4 | Refresh & Validate | 4-6 | 5.1-5.3 | No |
| 6.1 | FMCS Contract Expirations | 8-10 | None | FOIA request |
| 6.2 | NLRB Real-Time Monitor | 6-8 | None | No |
| 6.3 | FEC Political Data | 8-10 | None | Review PAC matches |
| 6.4 | DOL Enforcement (MSHA/OFCCP/EBSA) | 6-8 | None | No |
| 6.5 | Census Business Patterns | 4-6 | None | No |
| 6.6 | Mergent National Expansion | 10-15 | None | **CUNY extraction (3-5 hrs)** |
| 6.7 | State PERB Data | 6-8 | None | Public records requests |
| 7.1 | API Module Decomposition | 12-16 | None | No |
| 7.2 | Pagination & Validation | 8-10 | 7.1 | No |
| 7.3 | Authentication & Authorization | 12-15 | 7.1 | Admin credentials |
| 7.4 | Error Handling & Logging | 6-8 | 7.1 | No |
| 7.5 | API Versioning & Docs | 4-6 | 7.1 | No |
| 8.1 | Frontend Code Architecture | 8-10 | None | No |
| 8.2 | Accessibility (WCAG 2.1 AA) | 8-10 | None | No |
| 8.3 | Mobile Responsiveness | 6-8 | 8.1 | No |
| 8.4 | Error Recovery & Loading | 6-8 | None | No |
| 8.5 | UX Improvements | 6-8 | 8.1 | No |
| 9.1 | Containerization | 8-10 | 7.1 | No |
| 9.2 | Cloud Hosting Setup | 10-12 | 9.1 | **Create account, billing** |
| 9.3 | CI/CD Pipeline | 6-8 | 9.1 | No |
| 9.4 | Domain & SSL | 3-4 | 9.2 | **Register domain** |
| 9.5 | Monitoring & Alerting | 4-6 | 9.2 | No |
| 9.6 | Data Pipeline Automation | 8-10 | 7.1 | No |
| 10.1 | Historical Outcome Validation | 10-12 | 5.4 | No |
| 10.2 | Propensity Score Model | 10-14 | 10.1 | No |
| 10.3 | Composite Opportunity Score | 5-8 | 10.2 | No |
| 11.1 | User Documentation | 6-8 | 8.x | No |
| 11.2 | Developer Documentation | 4-6 | 7.x | No |
| 11.3 | Methodology Audit | 6-8 | 10.x | **Contact reviewers** |
| 11.4 | Beta Testing | 4-6 | 9.x, 11.1 | **Recruit testers** |
| 12.1 | Contract Expiration Alerts | 8-10 | 6.1, 7.3 | No |
| 12.2 | CPS Microdata | 10-12 | None | No |
| 12.3 | Occupation Mix Comparison | 10-14 | None | No |
| 12.4 | Text-Based Employer Embedding | 15-20 | None | No |
| 12.5 | Multi-Tenant Union Views | 10-12 | 7.3 | No |
| 12.6 | Campaign Tracking | 12-15 | 7.3 | No |
| 12.7 | News Monitoring | 10-12 | None | No |

**Total: 25 core checkpoints + 7 post-launch = 32 checkpoints**

---

*This roadmap was generated by a 5-agent research team analyzing the database (90+ tables, 33GB), API (142 endpoints, 7,500 lines), frontend (9,500 lines, 3 modes), new data sources (14 sources researched), and deployment infrastructure. It supersedes LABOR_PLATFORM_ROADMAP_v12.md and ROADMAP_TO_DEPLOYMENT.md v3.0.*

*Last updated: February 10, 2026*
